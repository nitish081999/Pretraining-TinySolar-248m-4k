{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a855d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from transformers import TextStreamer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import datasets\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3a057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def fix_torch_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "\n",
    "fix_torch_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b438eb15",
   "metadata": {},
   "source": [
    "# Loading a general pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66513fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='upstage/TinySolar-248m-4k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d48838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_general_model=AutoModelForCausalLM.from_pretrained(\n",
    "                      model_name,\n",
    "                      device_map='cpu',\n",
    "                      torch_dtype=torch.bfloat16\n",
    "                      )                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721c9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_general_tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0a0af",
   "metadata": {},
   "source": [
    "# Generate text samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1401e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"I am an engineer. I love\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607ad9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tiny_general_tokenizer(prompt, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd34157",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer=TextStreamer(tiny_general_tokenizer,skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f0a6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to travel and have a great time, but I'm not sure if I can do it all again.\n",
      "I've been working on my first book for the last 10 years, and I've always wanted to write about something that has happened in my life. It's been a long journey, but I've finally found my voice. I'm so excited to share this story with you!\n",
      "I'm a huge fan of the \"Sweet Home Alabama\" series, and I've read some of their books before. I've also enjoyed reading them as well. I've read\n"
     ]
    }
   ],
   "source": [
    "output=tiny_general_model.generate(**inputs, streamer=streamer, max_new_tokens=128,do_sample=False,temperature=0.0,repetition_penalty=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9673fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"def find_max(arr):\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db76a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tiny_general_tokenizer(prompt, return_tensors=\"pt\").to(tiny_general_model.device)\n",
    "\n",
    "streamer=TextStreamer(tiny_general_tokenizer,skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa60788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   \"\"\"\n",
      "   Returns the number of rows in a row.\n",
      "   \"\"\"\n",
      "   if not arr:\n",
      "       return 1\n",
      "   else:\n",
      "       return 0\n",
      "\n",
      "\n",
      "def get_rows(row):\n",
      "   \"\"\"\n",
      "   Returns the number of rows in a row.\n",
      "   \"\"\"\n",
      "   if len(row) == 2:\n",
      "       return 1\n",
      "   else:\n",
      "       return 0\n",
      "\n",
      "\n",
      "def get_rows_from_table(table, table_name):\n",
      "   \"\"\"\n",
      "   Returns the number of rows in a table.\n",
      "   \"\"\"\n",
      "   if len\n"
     ]
    }
   ],
   "source": [
    "outputs=tiny_general_model.generate(**inputs, streamer=streamer, max_new_tokens=128,do_sample=False,temperature=0.0,repetition_penalty=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87534c6b",
   "metadata": {},
   "source": [
    "# Generate Python samples with finetuned Python model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a95b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='upstage/TinySolar-248m-4k-code-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5f6a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_finetuned_model=AutoModelForCausalLM.from_pretrained(\n",
    "                      model_name,\n",
    "                      device_map='cpu',\n",
    "                      torch_dtype=torch.bfloat16\n",
    "                      )\n",
    "tiny_finetuned_tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888ab476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   max_len = arr[0]\n",
      "   max_len_index = 0\n",
      "   \n",
      "   for i in range(1, len(arr)):\n",
      "       if arr[i] > max_len:\n",
      "           max_len_index = i\n",
      "           \n",
      "   return max_len\n",
      "\n",
      "# Test the function\n",
      "arr = [5, 2, 9, 8, 3, 7, 6, 4, 2, 1, 8, 1, 6, 4, 2, 1, 6, 4, \n"
     ]
    }
   ],
   "source": [
    "prompt=\"def find_max(arr):\"\n",
    "\n",
    "inputs=tiny_finetuned_tokenizer(prompt, return_tensors=\"pt\").to(tiny_finetuned_model.device)\n",
    "\n",
    "streamer=TextStreamer(tiny_finetuned_tokenizer,skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "outputs=tiny_finetuned_model.generate(**inputs, streamer=streamer, max_new_tokens=128,do_sample=False,temperature=0.0,repetition_penalty=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc83b7",
   "metadata": {},
   "source": [
    "# Generate Python samples with pretrained Python model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b83451a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='upstage/TinySolar-248m-4k-py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "813470e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_general_model=AutoModelForCausalLM.from_pretrained(\n",
    "                      model_name,\n",
    "                      device_map='cpu',\n",
    "                      torch_dtype=torch.bfloat16\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "497da0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_general_tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fb66db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   \"\"\"Find the maximum number of numbers in a list.\"\"\"\n",
      "   max = 0\n",
      "   for num in numbers:\n",
      "       if num > max:\n",
      "           max = num\n",
      "   return max\n",
      "\n",
      "\n",
      "def get_min_max(numbers, min_value=1):\n",
      "   \"\"\"Get the minimum value of a list.\"\"\"\n",
      "   min_value = min_value or 1\n",
      "   for num in numbers:\n",
      "       if num < min_value:\n",
      "           min_value = num\n",
      "   return min_value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"def find_max(numbers):\"\n",
    "\n",
    "inputs=tiny_general_tokenizer(prompt, return_tensors=\"pt\").to(tiny_general_model.device)\n",
    "\n",
    "streamer=TextStreamer(tiny_general_tokenizer,skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "outputs=tiny_general_model.generate(**inputs, streamer=streamer, max_new_tokens=128,do_sample=False,temperature=0.0,repetition_penalty=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d818e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "pretraining_dataset = datasets.load_dataset(\n",
    "    \"upstage/Pretraining_Dataset\",\n",
    "    split=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5399d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'meta'],\n",
      "    num_rows: 60000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(pretraining_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f375990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_dataset=pretraining_dataset.select_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad3711a6-0f3c-4a86-a117-c8c2097914f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canada Pension Plan\n",
      "Find sources: \"Canada Pension Plan\" – news · newspapers · books · scholar · JSTOR (March 2013) (Learn how and when to remove this template message)\n",
      "The Canada Pension Plan (CPP; French: Régime de pensions du Canada) is a contributory, earnings-related social insurance program. It forms one of the two major components of Canada's public retirement income system, the other component being Old Age Security (OAS). Other parts of Canada's retirement system are private pensions, ei\n"
     ]
    }
   ],
   "source": [
    "print(pretraining_dataset[1]['text'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3572b-0940-4c34-a69c-08fffa78b3f8",
   "metadata": {},
   "source": [
    "# Instruction based dataset generated by chat gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4857d60b-faa9-4f14-840c-58176066c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 52002\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "instruction_dataset=datasets.load_dataset(\n",
    "    'c-s-ale/alpaca-gpt4-data',\n",
    "    split='train'\n",
    ")\n",
    "print(instruction_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8625d28-c6ec-4032-a1b4-503bb5aa26bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Give three tips for staying healthy.\n",
      "Input: \n",
      "Output: 1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n",
      "\n",
      "2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n",
      "\n",
      "3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "print('Instruction: '+instruction_dataset[i]['instruction']\n",
    "     +'\\nInput: '+instruction_dataset[i]['input']\n",
    "      +'\\nOutput: '+instruction_dataset[i]['output']\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f143565-0bc2-4c83-a3f3-9b7c6e74779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "#Path to directory to store python scripts\n",
    "\n",
    "code_dir=\"/home/nitish/Documents/GenAI/code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5280047f-d599-4e6c-957b-f221d40196d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://raw.githubusercontent.com/TheAlgorithms/Python/master/searches/double_linear_search_recursion.py\",\n",
    "    \"https://raw.githubusercontent.com/KosingZhu/tensorflow/master/tensorflow/python/tools/module_util.py\",\n",
    "    \"https://raw.githubusercontent.com/EricRemmerswaal/tensorflow/master/tensorflow/python/distribute/distribute_coordinator_context.py\",\n",
    "    \"https://raw.githubusercontent.com/computationalartist/tensorflow/master/tensorflow/python/ops/numpy_ops/integration_test/benchmarks/numpy_mlp.py\",\n",
    "    \"https://raw.githubusercontent.com/Van-an/tensorflow/master/tensorflow/python/distribute/coordinator/values.py\",\n",
    "    \"https://raw.githubusercontent.com/nkgwer/tensorflow/master/tensorflow/lite/tools/visualize.py\",\n",
    "    \"https://raw.githubusercontent.com/gitblazer/youtube-dl/master/youtube_dl/version.py\",\n",
    "    \"https://raw.githubusercontent.com/Joshua-Barawa/My-Photos/master/venv/lib/python3.8/site-packages/django/contrib/messages/__init__.py\",\n",
    "    \"https://raw.githubusercontent.com/PaliC/pytorch/master/test/fx/test_subgraph_rewriter.py\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fa9cbcd-a068-4689-811a-4537c9c85bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on url: https://raw.githubusercontent.com/TheAlgorithms/Python/master/searches/double_linear_search_recursion.py\n",
      "Working on url: https://raw.githubusercontent.com/KosingZhu/tensorflow/master/tensorflow/python/tools/module_util.py\n",
      "Working on url: https://raw.githubusercontent.com/EricRemmerswaal/tensorflow/master/tensorflow/python/distribute/distribute_coordinator_context.py\n",
      "Working on url: https://raw.githubusercontent.com/computationalartist/tensorflow/master/tensorflow/python/ops/numpy_ops/integration_test/benchmarks/numpy_mlp.py\n",
      "Working on url: https://raw.githubusercontent.com/Van-an/tensorflow/master/tensorflow/python/distribute/coordinator/values.py\n",
      "Working on url: https://raw.githubusercontent.com/nkgwer/tensorflow/master/tensorflow/lite/tools/visualize.py\n",
      "Working on url: https://raw.githubusercontent.com/gitblazer/youtube-dl/master/youtube_dl/version.py\n",
      "Working on url: https://raw.githubusercontent.com/Joshua-Barawa/My-Photos/master/venv/lib/python3.8/site-packages/django/contrib/messages/__init__.py\n",
      "Working on url: https://raw.githubusercontent.com/PaliC/pytorch/master/test/fx/test_subgraph_rewriter.py\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    print(f'Working on url: {url}')\n",
    "    response=requests.get(url)\n",
    "    file_name=os.path.basename(url)\n",
    "    file_path=os.path.join(code_dir,file_name)\n",
    "\n",
    "    with open(file_path,'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7725ce7a-c851-469e-9cda-88f15c1070dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double_linear_search_recursion.py\n",
      "values.py\n",
      "module_util.py\n",
      "visualize.py\n",
      "__pycache__\n",
      "test_subgraph_rewriter.py\n",
      "distribute_coordinator_context.py\n",
      "version.py\n",
      "__init__.py\n",
      "numpy_mlp.py\n"
     ]
    }
   ],
   "source": [
    "files=os.listdir(code_dir)\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "add591df-7378-4898-9eca-c8ae537ed23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dataset = []\n",
    "\n",
    "for item in os.listdir(code_dir):\n",
    "    path = os.path.join(code_dir, item)\n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as file:\n",
    "            code_dataset.append({'text': file.read()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22cd6257-58a5-488c-9542-169d57e163b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dataset=datasets.Dataset.from_list(code_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a8d5d97-c855-44bd-849d-7dc3abe50ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 60009\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset=datasets.concatenate_datasets(\n",
    "    [pretraining_dataset,code_dataset]\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40677bde-a28c-4452-804c-69079c9f7de6",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "977821b9-15c0-4121-99c7-fa19c918e24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60009"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb0d3a71-0328-4fb8-a158-16bf063c8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def paragraph_length_filter(x):\n",
    "    \"\"\"Returns False iff a page has too few lines or lines are too short\"\"\"\n",
    "    lines=x['text'].split('\\n')\n",
    "    if (\n",
    "        len(lines)<3 or min(heapq.nlargest(3,[len(line) for line in lines]))<3\n",
    "    ):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd8a62bc-ed99-421d-a6ab-f206e19a231b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3722056ad2a43dba520facbb15e6637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/60009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset=dataset.filter(\n",
    "    paragraph_length_filter,\n",
    "    load_from_cache_file=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8da7789e-e730-4556-9c68-230f840ee32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52357"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "678f543d-02b4-40e6-89b3-ee515e9be6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(paragraphs):\n",
    "    \"\"\"\n",
    "    use this function to find the number of repetitions in the paragraphs.\n",
    "    \"\"\"\n",
    "    unique_x=set()\n",
    "    duplicate_chars=0\n",
    "    duplicate_elements=0\n",
    "\n",
    "    for element in paragraphs:\n",
    "        if element in unique_x:\n",
    "            duplicate_chars+=len(element)\n",
    "            duplicate_elements+=1\n",
    "        else:\n",
    "            unique_x.add(element)\n",
    "    return duplicate_elements,duplicate_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb1e63b4-61e5-4df0-a2d4-91202377dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def paragraph_repetition_filter(x):\n",
    "    \"\"\"\n",
    "    Returns False iff a page has too many repetitions\n",
    "    \"\"\"\n",
    "    text=x['text']\n",
    "\n",
    "    paragraphs=re.compile(r'\\n{2,}').split(text.strip())\n",
    "    paragraphs_duplicates,char_duplicates=find_duplicates(paragraphs)\n",
    "\n",
    "    if paragraphs_duplicates/len(paragraphs)>0.2:\n",
    "        return False\n",
    "    if char_duplicates/len(text)>0.2:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4e5a1d7-ee47-437f-ba31-2045a27a1d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ad6165919f40b8a2a095b4c29e71a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/52357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset=dataset.filter(\n",
    "    paragraph_repetition_filter,\n",
    "    load_from_cache_file=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a284fdda-5a87-4c8d-b4ea-64aeda883c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52289"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "567c48eb-87b7-4b89-9b85-3763a6f180c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d74dad37cc44ae5931cd4f5afdc4f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/52289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def deduplications(ds):\n",
    "    def dedup_func(x):\n",
    "        \"\"\"Use this function to remove duplicate entries\"\"\"\n",
    "        if x['text'] in unique_text:\n",
    "            return False\n",
    "        else:\n",
    "            unique_text.add(x['text'])\n",
    "            return True\n",
    "    unique_text=set()\n",
    "\n",
    "    ds=ds.filter(dedup_func,load_from_cache_file=False,num_proc=1)\n",
    "    return ds\n",
    "\n",
    "dataset=deduplications(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bac1824b-4c04-4525-a368-336906f2baa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43566"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50557e13-c2bf-4729-a244-1f7f9462003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Parameter 'function'=<function english_language_filter.<locals>.is_english at 0x7edab7a36660> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d15154d20a9431f88874cfe3c502955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/43566 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import urllib\n",
    "from fasttext import load_model\n",
    "from fasttext.FastText import _FastText\n",
    "\n",
    "def english_language_filter(ds):\n",
    "    #load language detection model\n",
    "\n",
    "    current_dir = os.getcwd()\n",
    "    model_path = os.path.join(current_dir, \"lid.176.bin\")\n",
    "    \n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    def is_english(x):\n",
    "        #Predict language of the text and probability\n",
    "        language,score=model.predict(x['text'].replace('\\n',''))\n",
    "\n",
    "        language=language[0].split(\"__\")[2]\n",
    "\n",
    "        return score>0.4 and language=='en'\n",
    "\n",
    "    ds=ds.filter(is_english,load_from_cache_file=False,num_proc=1)\n",
    "\n",
    "    return ds\n",
    "\n",
    "dataset=english_language_filter(dataset)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67995454-de25-4fbc-96e9-9483ca123ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40454"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4df2cf44-203c-4a1f-9386-d6672207605f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697c19dce3bb4f8984e8c2b2523665a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/41 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "196961832"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path='./preprocessed_dataset.parquet'\n",
    "dataset.to_parquet(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4360f3d-051b-4986-a081-bf6194ce4b2b",
   "metadata": {},
   "source": [
    "# Packing Data for Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1153dc-e407-4687-9b16-05f63dcd5f80",
   "metadata": {},
   "source": [
    "# 1.Tokenizing and Creating input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e17dd8f-efc4-47c3-b910-1f542274fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8a2e7af-2b10-4ade-a050-c4c1928dac6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b323979e00ab4ecb9b863071c74fbe4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 40454\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset=datasets.load_dataset(\n",
    "    'parquet',\n",
    "    data_files=\"./preprocessed_dataset.parquet\",\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1deb933e-effe-4850-b3b4-d50848188799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 4046\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset.shard(num_shards=10,index=0)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f63c8ed-929f-4a64-8c51-b78e32184e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name='upstage/SOLAR-10.7B-v1.0'\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee875c86-a5f8-4c20-bc76-9f676cd4759e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁I', \"'\", 'm', '▁a', '▁N', 'it', 'ish']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"I'm a Nitish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78d6f557-d633-434e-95a8-39547e1ffb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(example):\n",
    "    #Tokenize\n",
    "    tokens=tokenizer.tokenize(example['text'])\n",
    "\n",
    "    #convert tokens to ids\n",
    "    token_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    #Add <bos>,<eos> token to the front and back of token_ids\n",
    "    #bos: begin of sequence, eos: end of sequence\n",
    "    token_ids=[\n",
    "        tokenizer.bos_token_id]\\\n",
    "        +token_ids \\\n",
    "        +[tokenizer.eos_token_id\n",
    "    ]\n",
    "    example['input_ids']=token_ids\n",
    "\n",
    "    #we will be using this column to count the total number of tokens\n",
    "    #in this final dataset\n",
    "\n",
    "    example['num_tokens']=len(token_ids)\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "faf7f878-36db-4e37-8034-9b47130dfda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eac7544a5574bc4ab83908d9f2af992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'input_ids', 'num_tokens'],\n",
      "    num_rows: 4046\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset.map(tokenization,load_from_cache_file=False)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d08d35e-f5e9-4103-9010-ac2a9a08a3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Adele Hall nee: Grant\n",
      "Adele (G\n",
      "\n",
      "input_ids [1, 330, 450, 291, 6756, 435, 28706, 28747, 14301, 13, 28741, 450, 291, 325, 28777, 6804, 28731, 6756, 4568, 1753, 356, 10983, 28725, 4624, 28705, 28750, 28783, 28725, 28705, 28750]\n",
      "\n",
      "num_tokens 579\n"
     ]
    }
   ],
   "source": [
    "sample=dataset[41]\n",
    "\n",
    "print('Text',sample['text'][:30])\n",
    "print('\\ninput_ids',sample['input_ids'][:30])\n",
    "print('\\nnum_tokens',sample['num_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4c1b269-534f-4501-9b19-87af77857bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5303633"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.sum(dataset['num_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d6243cf-11e6-4970-b55f-2d3d524a873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5303633\n"
     ]
    }
   ],
   "source": [
    "input_ids=np.concatenate(dataset['input_ids'])\n",
    "print(len(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f179323-b364-43a3-98cf-f810a23ed069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A longer maximum sequence length will enable better performance for long text\n",
    "max_seq_length=32\n",
    "#solar and llama-2 uses 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30684d9c-9a96-4de5-a5a1-277b55e24ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length=len(input_ids)-len(input_ids)%max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "111fd56c-50a2-4ac4-88ea-b0436b61769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5303616\n"
     ]
    }
   ],
   "source": [
    "print(total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15f048bb-4bfa-4fb8-b4f0-ca74486e8db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5303616,)\n"
     ]
    }
   ],
   "source": [
    "input_ids=input_ids[:total_length]\n",
    "print(input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "183923c0-b529-4539-88d6-872181603cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165738, 32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_reshaped=input_ids.reshape(-1,max_seq_length).astype(np.int32)\n",
    "input_ids_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7d8bc48-5ab3-46e3-9947-02232130a38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_ids_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "343419f9-d5bb-4e7d-ba0d-0304fe001161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids'],\n",
      "    num_rows: 165738\n",
      "})\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "#Transforming out input_ids into a list\n",
    "input_ids_list=input_ids_reshaped.tolist()\n",
    "\n",
    "#Transforming our list into dictionary\n",
    "packaged_pretrain_dataset=datasets.Dataset.from_dict(\n",
    "    {'input_ids':input_ids_list}\n",
    ")\n",
    "\n",
    "print(packaged_pretrain_dataset)\n",
    "print(type(packaged_pretrain_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe9b6836-43c6-4c77-89cf-ff8b61afbf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880c62c679f5422f85a7df21ce81ab58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/166 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21877416"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packaged_pretrain_dataset.to_parquet('./packages_pretrain_dataset.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed4e1f-4e93-492e-a2ee-ce67841f7229",
   "metadata": {},
   "source": [
    "# Preparing our model for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a4cc7-d884-43c2-b88f-6d8df782ab13",
   "metadata": {},
   "source": [
    "# 1. Model configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5623033f-6bf9-46ed-bf37-a705e1981af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.37.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaConfig\n",
    "\n",
    "config=LlamaConfig()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23d3d320-2c39-4a89-8bd0-a85157450f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.37.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config.num_hidden_layers=12   #reduced from 32 to 12\n",
    "config.hidden_size=1024       #reduced 1/4 from 4096 to 1024\n",
    "config.intermediate_size=4096 #reduced 1/3 from 11008 to 4096\n",
    "config.num_key_value_heads=8  #reduced 1/4 from 32 to 8 \n",
    "config.torch_dtype='bfloat16' # for half-precision training\n",
    "config.use_cache=False        #`True` is incompatible w/ gradient\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea41e08-3ecf-469d-a457-c3681d7039fa",
   "metadata": {},
   "source": [
    "# 2 Weight initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c186a15-d1fd-4698-b360-b728345d5c22",
   "metadata": {},
   "source": [
    "# 2.1 Random weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f555061-e740-4009-a39b-559b37965a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (k_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "          (down_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "model=LlamaForCausalLM(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf834395-7dae-4163-aad5-da6a33b33705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of parameters is: 248013824\n"
     ]
    }
   ],
   "source": [
    "def print_nparams(model):\n",
    "    \"\"\"Calculate the total number of model parameters\"\"\"\n",
    "    nparams=sum(p.numel() for p in model.parameters())\n",
    "    print(f'The total number of parameters is: {nparams}')\n",
    "\n",
    "print_nparams(model)  #248013824 =>248M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04c5329c-8de4-4975-a250-bbb61cf07a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 weights of layer'model.layers.0.self_attn.q_proj.weight':\n",
      "tensor([ 1.5794e-02, -2.2748e-02,  2.0156e-02, -2.6072e-02, -8.3267e-05,\n",
      "         8.7432e-03, -9.0255e-04, -4.2442e-02,  1.5337e-02,  1.4482e-02,\n",
      "         1.3526e-02,  1.9171e-03, -2.3141e-02, -4.2336e-03,  6.9818e-04,\n",
      "         8.9955e-03, -2.0524e-02, -1.3378e-02,  2.3255e-02,  9.5167e-04,\n",
      "         2.1053e-02,  1.2794e-02, -7.6783e-03, -3.7832e-03, -8.9180e-03,\n",
      "         7.4018e-04, -2.5204e-02, -1.7069e-02,  1.3481e-03,  4.7622e-02])\n"
     ]
    }
   ],
   "source": [
    "layer_name=\"model.layers.0.self_attn.q_proj.weight\"\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    if name==layer_name:\n",
    "        print(f\"First 30 weights of layer'{layer_name}':\")\n",
    "        print(param.data.view(-1)[:30])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb5c7919-f4f5-4bb3-87de-94971b427c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possessed possessed possessed possessed possessed possessedcontinuecontinuecontinuecontinuecontinueDownloadџcontinueDownloadcontinueDownloadcontinueertsxE Point remoterts remoterts remoterts갑continuecontinuecontinue wide wide atr wide atr wide wide wide wide wide wide wide wide wide wide wide wideursor otra FC otraopesopesopesopesopesopesopesopesopesopesopes wideopes wideopes wideopes wideopes wideopes wideopes wideopesimpse Library wideopesasterasterasterasterasterasterasterasterasterasterasterasterasterasterasterasterasterasterasteraster primarily primarily primarily primarily primarily primarily primarilyasterasterasterasterasterasterasterasterasterasterasteraster primarilyitä primarilyitä primarilyitä primarilyitä primarilyitä primarilyitä primarilyitä primarilyitä primarilyasterpriseasterpriseasterpriseaster\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "\n",
    "model_dir='upstage/SOLAR-10.7B-v1.0'\n",
    "\n",
    "tokenizer=LlamaTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "from transformers import TextStreamer\n",
    "\n",
    "prompt='I am an engineer. I love'\n",
    "\n",
    "inputs=tokenizer(prompt,return_tensors='pt').to(model.device)\n",
    "\n",
    "streamer=TextStreamer(\n",
    "    tokenizer,\n",
    "    skip_prompt=True,\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    streamer=streamer,\n",
    "    use_cache=True,\n",
    "    max_length=128 + len(prompt),  # Adjust the max length here\n",
    "    do_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f701cff-e578-4f9c-b5eb-7bd120d5823d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note: we're running large models in a limited environment\n",
    "import gc\n",
    "del model\n",
    "del streamer\n",
    "del outputs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b376890-6fd4-4f15-8b91-736a4df02504",
   "metadata": {},
   "source": [
    "# 3. Reuse general pretrained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b9099ef-328a-42ab-9cb3-a409fbda3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_name='upstage/TinySolar-248m-4k'\n",
    "\n",
    "model=AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='cpu',\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35846a43-43ec-4e87-9074-4ac830ed9b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b9cd4-d35a-49c9-b123-f74e473e6722",
   "metadata": {},
   "source": [
    "# 4. Downscaling from a general pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2af12b2-4416-425d-88cd-af01a9c9659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoConfig\n",
    "\n",
    "model_name='upstage/TinySolar-248m-4k'\n",
    "\n",
    "model=AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='cpu',\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2c1c6b2-9a3e-4c1c-852e-dc2c1f9b8af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (k_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "          (down_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "137869b1-14a0-407e-b202-fcc2f4efa9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-9): 10 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (k_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "          (down_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "layers=model.model.layers\n",
    "\n",
    "model.model.layers=layers[:5]+layers[-5:]\n",
    "\n",
    "config=AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_hidden_layers=len(model.model.layers)\n",
    ")\n",
    "\n",
    "model.config=config\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d7fc3ed-633c-480b-a505-31c4c8155c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of parameters is: 217601024\n"
     ]
    }
   ],
   "source": [
    "print_nparams(model) #217M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66153a94-ad02-411e-accf-9aac907e84b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf16dfbe-ca29-4f31-ae3d-50cb10cff41d",
   "metadata": {},
   "source": [
    "# 5. Depth Upscaling from a general pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3418aa87-55fb-4122-81ed-b6ee2f243efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.37.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config=LlamaConfig(\n",
    "    num_hidden_layers=16,\n",
    "    hidden_size=1024,\n",
    "    intermediate_size=4096,\n",
    "    num_attention_heads=32,\n",
    "    num_key_value_heads=8,\n",
    "    torch_dtype='bfloat16',\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9dd4b43-5edf-45f2-b327-b5a4da51615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of parameters is: 308839424\n"
     ]
    }
   ],
   "source": [
    "model = LlamaForCausalLM(config)\n",
    "model = model.to(dtype=torch.bfloat16)  # convert to bfloat16\n",
    "print_nparams(model)  #308M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "115eafd9-d236-4b84-bd84-0e0a2b5cc44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of parameters is: 248013824\n"
     ]
    }
   ],
   "source": [
    "model_name='upstage/TinySolar-248m-4k'\n",
    "\n",
    "pretrained_model=AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='cpu',\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print_nparams(pretrained_model)  #248M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6bde83ef-d703-453a-afe9-f80dcc444eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.37.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "model.model.layers=deepcopy(pretrained_model.model.layers[:-4])\\\n",
    "                    +deepcopy(pretrained_model.model.layers[4:])\n",
    "\n",
    "model.model.embed_tokens=deepcopy(pretrained_model.model.embed_tokens)\n",
    "\n",
    "model.lm_head=deepcopy(pretrained_model.lm_head)\n",
    "\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8ca43b2e-0ac7-437d-88d6-e6e949633b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of parameters is: 308839424\n"
     ]
    }
   ],
   "source": [
    "print_nparams(model)  #308M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e2ef9ef-29f7-47fd-93f3-fc4bba24b5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to work with people who are not afraid to look at the world and are not afraid to look at the world with a little bit of a twist.\n",
      "I am a very humble person and I am very fortunate to have a great team of people who work hard to make a difference.\n",
      "I am very fortunate to have a great team of people who work hard to make a difference.\n",
      "I am very fortunate to have a great team of people who work hard to make a difference.\n",
      "I am very fortunate to have a great team of people who work hard to make a difference.\n",
      "I am very fortunate to have a great team\n"
     ]
    }
   ],
   "source": [
    "prompt=\"I am an engineer. I love\"\n",
    "\n",
    "inputs=tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "\n",
    "streamer=TextStreamer(\n",
    "    tokenizer,\n",
    "    skip_prompt=True,\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "outputs=model.generate(\n",
    "    **inputs,\n",
    "    streamer=streamer,\n",
    "    use_cache=True,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "96faf91d-88af-4dcb-8c1f-3c7ec33f30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./TinySolar-308-4k-init')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1d8f4-e542-46d9-9536-82ecf20aedf4",
   "metadata": {},
   "source": [
    "# Training in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "962d07ef-4af8-4bb6-8446-a7b258bf9762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (down_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f92e32-4d94-4622-a4fb-1e718ea3f6e2",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0c3e1ea0-22bb-4207-9802-84d76f920d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,args,split='train'):\n",
    "        self.args=args\n",
    "        self.dataset=datasets.load_dataset('parquet',data_files=args.dataset_name,split=split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        #convert the list to a longtensor for pythorch\n",
    "\n",
    "        input_ids=torch.LongTensor(self.dataset[idx]['input_ids'])\n",
    "        labels=torch.LongTensor(self.dataset[idx]['input_ids'])\n",
    "\n",
    "        #Return the sample as a dicdtionary\n",
    "        return {'input_ids':input_ids,'labels':labels}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea45d9-9344-45b7-a912-6e69e5692a7f",
   "metadata": {},
   "source": [
    "# Configure Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "119f75e4-d3b7-4aa8-8f8b-98c9ee2f8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import transformers\n",
    "\n",
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    dataset_name: str = field(                           # Dataset configuration\n",
    "        default=\"./packages_pretrain_dataset.parquet\")\n",
    "    num_proc: int = field(default=1)                     # Number of subprocesses for data preprocessing\n",
    "    max_seq_length: int = field(default=32)              # Maximum sequence length\n",
    "\n",
    "    # Core training configurations\n",
    "    seed: int = field(default=0)                         # Random seed for initialization, ensuring reproducibility\n",
    "    optim: str = field(default=\"adamw_torch\")            # Optimizer, here it's AdamW implemented in PyTorch\n",
    "    max_steps: int = field(default=30)                   # Number of maximum training steps\n",
    "    per_device_train_batch_size: int = field(default=2)  # Batch size per device during training\n",
    "\n",
    "    # Other training configurations\n",
    "    learning_rate: float = field(default=5e-5)           # Initial learning rate for the optimizer\n",
    "    weight_decay: float = field(default=0)               # Weight decay\n",
    "    warmup_steps: int = field(default=10)                # Number of steps for the learning rate warmup phase\n",
    "    lr_scheduler_type: str = field(default=\"linear\")     # Type of learning rate scheduler\n",
    "    gradient_checkpointing: bool = field(default=True)   # Enable gradient checkpointing to save memory\n",
    "    dataloader_num_workers: int = field(default=2)       # Number of subprocesses for data loading\n",
    "    bf16: bool = field(default=True)                     # Use bfloat16 precision for training on supported hardware\n",
    "    gradient_accumulation_steps: int = field(default=1)  # Number of steps to accumulate gradients before updating model weights\n",
    "    \n",
    "    # Logging configuration\n",
    "    logging_steps: int = field(default=3)                # Frequency of logging training information\n",
    "    report_to: str = field(default=\"none\")               # Destination for logging (e.g., WandB, TensorBoard)\n",
    "\n",
    "    # Saving configuration\n",
    "    # save_strategy: str = field(default=\"steps\")          # Can be replaced with \"epoch\"\n",
    "    # save_steps: int = field(default=3)                   # Frequency of saving training checkpoint\n",
    "    # save_total_limit: int = field(default=2)             # The total number of checkpoints to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3fd1f6c0-0998-43c8-8a9f-b17078479b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda=True,\n",
    "use_cpu=True\n",
    "fp16=False,\n",
    "bf16=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34ba2d49-80d0-4675-8383-0405d0baa269",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = transformers.HfArgumentParser(CustomArguments)\n",
    "args, = parser.parse_args_into_dataclasses(\n",
    "    args=[\"--output_dir\", \"output\", \"--no_cuda\", \"True\", \"--use_cpu\", \"True\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aa52f862-4c51-4c79-a677-4d43fe6c0a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=CustomDataset(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4d36b9ab-d41c-43fd-8878-ed4f30d797f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print('Input shape: ',train_dataset[0]['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1eeb0e3e-45f4-43b1-bc7a-924bf3b0a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer,TrainingArguments,TrainerCallback\n",
    "\n",
    "#Define a custom callback to log the loss values\n",
    "\n",
    "class LossLoggingCallback(TrainerCallback):\n",
    "    def on_log(self,args,state,control,logs=None,**kwargs):\n",
    "        if logs is not None:\n",
    "            self.logs.append(logs)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.logs=[]\n",
    "\n",
    "loss_logging_callback=LossLoggingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eeeffd2f-e1ef-4cd3-8b11-1ad055c14f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 34:06, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.722600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.698200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.284600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>4.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>4.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>4.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.944500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=4.019758351643881, metrics={'train_runtime': 2128.2922, 'train_samples_per_second': 0.028, 'train_steps_per_second': 0.014, 'total_flos': 2479631892480.0, 'train_loss': 4.019758351643881, 'epoch': 0.0})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer=Trainer(\n",
    "    model=pretrained_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=None,\n",
    "    callbacks=[loss_logging_callback]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa75736-c81b-4205-99c7-82daaab74d10",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "36b74fb4-ba11-47ef-a480-a46f8006a959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/EleutherAI/lm-evaluation-harness\n",
      "  Cloning https://github.com/EleutherAI/lm-evaluation-harness to /tmp/pip-req-build-38x3eabl\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm-evaluation-harness /tmp/pip-req-build-38x3eabl\n",
      "  Resolved https://github.com/EleutherAI/lm-evaluation-harness to commit 42dc244867889a19ae80847254a481f446f6e4b7\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.26.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.26.1)\n",
      "Collecting evaluate (from lm_eval==0.4.3)\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from lm_eval==0.4.3) (2.16.1)\n",
      "Collecting jsonlines (from lm_eval==0.4.3)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting numexpr (from lm_eval==0.4.3)\n",
      "  Downloading numexpr-2.10.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting peft>=0.2.0 (from lm_eval==0.4.3)\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from lm_eval==0.4.3) (2.13.1)\n",
      "Collecting pytablewriter (from lm_eval==0.4.3)\n",
      "  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting rouge-score>=0.0.4 (from lm_eval==0.4.3)\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu>=1.5.0 (from lm_eval==0.4.3)\n",
      "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn>=0.24.1 (from lm_eval==0.4.3)\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting sqlitedict (from lm_eval==0.4.3)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from lm_eval==0.4.3) (2.1.2)\n",
      "Collecting tqdm-multiprocess (from lm_eval==0.4.3)\n",
      "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: transformers>=4.1 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from lm_eval==0.4.3) (4.37.2)\n",
      "Requirement already satisfied: zstandard in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.22.0)\n",
      "Requirement already satisfied: dill in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.3.7)\n",
      "Collecting word2number (from lm_eval==0.4.3)\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: more-itertools in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from lm_eval==0.4.3) (10.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (24.1)\n",
      "Requirement already satisfied: psutil in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (0.24.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (0.6)\n",
      "Requirement already satisfied: pandas in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.3) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.9.5)\n",
      "Collecting absl-py (from rouge-score>=0.0.4->lm_eval==0.4.3)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting nltk (from rouge-score>=0.0.4->lm_eval==0.4.3)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.3) (1.16.0)\n",
      "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==0.4.3)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (2024.5.15)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu>=1.5.0->lm_eval==0.4.3)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting colorama (from sacrebleu>=1.5.0->lm_eval==0.4.3)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu>=1.5.0->lm_eval==0.4.3)\n",
      "  Downloading lxml-5.2.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn>=0.24.1->lm_eval==0.4.3)\n",
      "  Using cached scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.24.1->lm_eval==0.4.3)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.1->lm_eval==0.4.3)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm_eval==0.4.3) (12.5.82)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from transformers>=4.1->lm_eval==0.4.3) (0.15.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from jsonlines->lm_eval==0.4.3) (23.1.0)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.3) (69.5.1)\n",
      "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval==0.4.3)\n",
      "  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.4.3)\n",
      "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.4.3)\n",
      "  Downloading pathvalidate-3.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.4.3)\n",
      "  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.4.3)\n",
      "  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3)\n",
      "  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.9.4)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.3) (4.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.3) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.3) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.9 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3) (2024.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from jinja2->torch>=1.8->lm_eval==0.4.3) (2.1.3)\n",
      "Requirement already satisfied: click in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.3) (8.1.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->lm_eval==0.4.3) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages (from sympy->torch>=1.8->lm_eval==0.4.3) (1.3.0)\n",
      "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading numexpr-2.10.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (406 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.7/406.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
      "Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
      "Using cached scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading lxml-5.2.2-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: lm_eval, rouge-score, sqlitedict, word2number\n",
      "  Building wheel for lm_eval (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lm_eval: filename=lm_eval-0.4.3-py3-none-any.whl size=1947043 sha256=80a56b4e3eca6402c2c0e8a76d711df80d21b7ade470fa3f0a41710af34aaa14\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-c5nj5gw9/wheels/1a/a8/64/595bbe908ea9add178046b326d8fcd3f51f1855461cca66285\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=f79a58f5fa6991f1aa4112a1654ce7529bbeee65a9767cabf29667e66c2f7776\n",
      "  Stored in directory: /home/nitish/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=f7d8d643ab2c200048764201d554f5eedf696c432e8e4ac68ba4a0d021bb2a5c\n",
      "  Stored in directory: /home/nitish/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=c3b045397b65c0411dc017009033d51c331e4964863208b8aa710013b4669ab0\n",
      "  Stored in directory: /home/nitish/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
      "Successfully built lm_eval rouge-score sqlitedict word2number\n",
      "Installing collected packages: word2number, sqlitedict, threadpoolctl, tcolorpy, tabulate, scipy, portalocker, pathvalidate, numexpr, mbstrdecoder, lxml, jsonlines, joblib, colorama, absl-py, typepy, tqdm-multiprocess, scikit-learn, sacrebleu, nltk, rouge-score, DataProperty, tabledata, peft, evaluate, pytablewriter, lm_eval\n",
      "Successfully installed DataProperty-1.0.1 absl-py-2.1.0 colorama-0.4.6 evaluate-0.4.2 joblib-1.4.2 jsonlines-4.0.0 lm_eval-0.4.3 lxml-5.2.2 mbstrdecoder-1.1.3 nltk-3.8.1 numexpr-2.10.1 pathvalidate-3.2.0 peft-0.12.0 portalocker-2.10.1 pytablewriter-1.2.0 rouge-score-0.1.2 sacrebleu-2.4.2 scikit-learn-1.5.1 scipy-1.14.0 sqlitedict-2.1.0 tabledata-1.3.3 tabulate-0.9.0 tcolorpy-0.1.6 threadpoolctl-3.5.0 tqdm-multiprocess-0.0.11 typepy-1.3.2 word2number-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/EleutherAI/lm-evaluation-harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5110d7f1-ca55-42df-9c14-dfcb7c9d9bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-24:22:21:44,740 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2024-07-24:22:21:46,256 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2024-07-24:22:21:48,245 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,247 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,249 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,251 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,252 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,254 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,256 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,258 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,259 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,261 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,263 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,265 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,267 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,269 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,270 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,272 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,274 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,276 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,278 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,280 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,282 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,283 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,285 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,287 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,289 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,291 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,293 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,295 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,297 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,299 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,300 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,302 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,304 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,306 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,308 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,310 INFO     [__init__.py:512] The tag mmlu is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,566 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,567 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,569 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,571 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,572 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,574 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,576 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,578 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,579 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,581 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,583 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,584 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,586 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,588 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,589 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,591 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,593 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,594 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,596 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,598 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,599 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,601 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,602 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,604 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,606 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,607 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,609 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,610 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,612 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,614 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,615 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,617 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,619 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,623 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,633 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,636 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,639 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,644 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,647 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,650 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,652 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,654 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,657 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,660 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,662 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,663 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,665 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,667 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,668 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,670 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,671 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,673 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,675 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,677 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,679 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,680 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,682 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,683 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,685 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,686 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,688 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,690 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,692 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,693 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,695 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,696 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,698 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,699 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,701 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,702 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,704 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,706 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,708 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,709 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,711 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,712 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,715 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,716 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,718 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,720 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,721 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,723 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,725 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,727 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,729 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,731 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,732 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,734 INFO     [__init__.py:512] The tag xnli is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-07-24:22:21:48,942 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2024-07-24:22:21:48,943 INFO     [__main__.py:376] Selected Tasks: ['truthfulqa_mc2']\n",
      "2024-07-24:22:21:48,945 INFO     [evaluator.py:158] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-07-24:22:21:48,945 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': './upstage/TinySolar-248m-4k'}\n",
      "2024-07-24:22:21:48,952 INFO     [huggingface.py:170] Using device 'cpu'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/utils/hub.py\", line 385, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n",
      "    validate_repo_id(arg_value)\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n",
      "    raise HFValidationError(\n",
      "huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './upstage/TinySolar-248m-4k'. Use `repo_type` argument if needed.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/lm_eval/__main__.py\", line 382, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/lm_eval/utils.py\", line 397, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 198, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/lm_eval/api/model.py\", line 147, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 196, in __init__\n",
      "    self._get_config(\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 469, in _get_config\n",
      "    self._config = transformers.AutoConfig.from_pretrained(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1100, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 634, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/home/nitish/anaconda3/envs/myenv/lib/python3.11/site-packages/transformers/utils/hub.py\", line 450, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: Incorrect path_or_model_id: './upstage/TinySolar-248m-4k'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=./upstage/TinySolar-248m-4k \\\n",
    "    --tasks truthfulqa_mc2 \\\n",
    "    --device cpu \\\n",
    "    --limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417415d-3d7a-4438-a7b1-f8d8dfca91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def h6_open_llm_leaderboard(model_name):\n",
    "  task_and_shot = [\n",
    "      ('arc_challenge', 25),\n",
    "      ('hellaswag', 10),\n",
    "      ('mmlu', 5),\n",
    "      ('truthfulqa_mc2', 0),\n",
    "      ('winogrande', 5),\n",
    "      ('gsm8k', 5)\n",
    "  ]\n",
    "\n",
    "  for task, fewshot in task_and_shot:\n",
    "    eval_cmd = f\"\"\"\n",
    "    lm_eval --model hf \\\n",
    "        --model_args pretrained={model_name} \\\n",
    "        --tasks {task} \\\n",
    "        --device cpu \\\n",
    "        --num_fewshot {fewshot}\n",
    "    \"\"\"\n",
    "    os.system(eval_cmd)\n",
    "\n",
    "h6_open_llm_leaderboard(model_name=\"YOUR_MODEL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01085c8560be4152be8ab67b4a9284aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0b301b0bd3e04894a6bf4087aac50566",
       "style": "IPY_MODEL_f6b53f077ab14cc0a6055bfdb34c2549",
       "value": " 1/1 [00:00&lt;00:00, 74.75it/s]"
      }
     },
     "013b90256615450cb249ab49d4b7a9f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "02649950dc764b818bc58894a1d49ddd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "080fa2419ade4ec08b17652f360c4c5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a6166f4e27d54f78a83c20a0575d4df9",
       "max": 1,
       "style": "IPY_MODEL_b032309e20c441ddaf5be7252244779b",
       "value": 1
      }
     },
     "09db7251fbef49f8a5b46fc16d77e4fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0b301b0bd3e04894a6bf4087aac50566": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0d15154d20a9431f88874cfe3c502955": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_814cb063450a416096dad0b32cfd2786",
        "IPY_MODEL_903adaee46324e46aeee9fed0cb09b7e",
        "IPY_MODEL_12970d8c21a04a26a79d1e1a0615959c"
       ],
       "layout": "IPY_MODEL_5031c7c093754579a64a3111781dd612"
      }
     },
     "12970d8c21a04a26a79d1e1a0615959c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_629ca1be11f04c8295fb3fdf319e96a5",
       "style": "IPY_MODEL_df76079e34c24e1abcc985d0a117f5a4",
       "value": " 43566/43566 [00:16&lt;00:00, 2650.29 examples/s]"
      }
     },
     "12b5b879db844c65b7505585f6f46d47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3c4f4f03f1294b42bc2c67a02cd1c654",
       "max": 52357,
       "style": "IPY_MODEL_5e03f91cb59d4ad4af22d826b6f63f71",
       "value": 52357
      }
     },
     "14c96af1dd004f168f2080bd34c2492d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "159d71d3dbc34f8a81294607629a264b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "15ad6165919f40b8a2a095b4c29e71a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_199e2005b28a4d07ac17cca271cd2795",
        "IPY_MODEL_12b5b879db844c65b7505585f6f46d47",
        "IPY_MODEL_c76f5899fca245f8ad6bd9037955f491"
       ],
       "layout": "IPY_MODEL_ce3c41a40a9744f99741e31a976879de"
      }
     },
     "1903fdb22d374741a21e57b6e5d48ac7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_159d71d3dbc34f8a81294607629a264b",
       "style": "IPY_MODEL_eb545fe0cc154f59a68ecadc8e23599f",
       "value": "Filter: 100%"
      }
     },
     "194615113ec940e58b7cd643203019d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1fa22db695374b9f8f07c729598d0853",
       "style": "IPY_MODEL_450c5271c14a4d55bdb33990c75f786e",
       "value": "Computing checksums: 100%"
      }
     },
     "199e2005b28a4d07ac17cca271cd2795": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bdb22c309ede486d927b314b10fee322",
       "style": "IPY_MODEL_09db7251fbef49f8a5b46fc16d77e4fe",
       "value": "Filter: 100%"
      }
     },
     "1b1f9a847bac4688a828da78d6f027c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1b7ad33b704a48a38f5370cb18293dd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1bf51635bc3c49e687c8c29093be0930": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1d4e95213ffc46a1b2af8e96deb89a53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e35e99b0dc19410b9b336f563283cf58",
       "style": "IPY_MODEL_c7214698a5944809bc9091e9ae0ddfcc",
       "value": " 4046/4046 [00:18&lt;00:00, 126.00 examples/s]"
      }
     },
     "1dc03b0b2b2049efa02d9e7c98ee7c7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1bf51635bc3c49e687c8c29093be0930",
       "style": "IPY_MODEL_e72194c52849412ebc8c20973026866b",
       "value": " 165738/0 [00:00&lt;00:00, 2118020.65 examples/s]"
      }
     },
     "1f564073f4db4f8fb7dcc6f6f2c76f82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1fa22db695374b9f8f07c729598d0853": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1ff13d7e83464fdd8aba8cb07a3a1883": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8b6566c40dfa41cc92be7941a6984583",
       "style": "IPY_MODEL_b35b2dbf88bf4b83b216aecaebca96b2",
       "value": "Creating parquet from Arrow format: 100%"
      }
     },
     "23da90d9d33147f68e12acaf7f9034d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9d2947a86f8943fca886bcedd50e6d7d",
       "style": "IPY_MODEL_02649950dc764b818bc58894a1d49ddd",
       "value": "Filter: 100%"
      }
     },
     "28dcb40d09ed45b5b550a49e0a0302ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "29010c338d38458f859c4311f01b079a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2ace827b7fc244b7ac210dfedb52fb70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_cb323e88c7864cb19a0ea00be9349cc7",
       "max": 166,
       "style": "IPY_MODEL_585d5fdfeb674b55a42f0f33866e4c5d",
       "value": 166
      }
     },
     "2c76bae7f31a4b4db91d2a49ed648479": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2d3749e3a4294cb7a293ba017d9c6536": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a37484eee035441bb959e42a67c0977f",
       "style": "IPY_MODEL_326b96704490433781c0edebb345e263",
       "value": "Computing checksums: 100%"
      }
     },
     "2d74dad37cc44ae5931cd4f5afdc4f7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_23da90d9d33147f68e12acaf7f9034d1",
        "IPY_MODEL_3b9eeec0b1214d08b3d0c112c42ccd6e",
        "IPY_MODEL_4535b7ce43494673a6842df72a315d8c"
       ],
       "layout": "IPY_MODEL_b0d6879f4b4641ffb8cd537e1fc59a0d"
      }
     },
     "2e1efcc879b04464b472d6f5bbeecce8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "326b96704490433781c0edebb345e263": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "33b12c15a3fa4d16b31c17604880082d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "36270fd99b2b44d1aa9965d320b4d8a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2d3749e3a4294cb7a293ba017d9c6536",
        "IPY_MODEL_919a6da401ad42f5bba61504052d379d",
        "IPY_MODEL_7ec8704277334b6398183263e0cc9182"
       ],
       "layout": "IPY_MODEL_b9560212a7464979828d42e198e1e7ce"
      }
     },
     "3b9eeec0b1214d08b3d0c112c42ccd6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f038f9d849ac479f86d63c7971e28cab",
       "max": 52289,
       "style": "IPY_MODEL_f7023110ef0d4b518977a64d7bc3d409",
       "value": 52289
      }
     },
     "3c4f4f03f1294b42bc2c67a02cd1c654": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3d2f6a261d444070ab267e8f02fb7501": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_013b90256615450cb249ab49d4b7a9f6",
       "style": "IPY_MODEL_28dcb40d09ed45b5b550a49e0a0302ea",
       "value": "Map: 100%"
      }
     },
     "3eac7544a5574bc4ab83908d9f2af992": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3d2f6a261d444070ab267e8f02fb7501",
        "IPY_MODEL_adc1ea79bac6429897f5e535c94a7cd6",
        "IPY_MODEL_1d4e95213ffc46a1b2af8e96deb89a53"
       ],
       "layout": "IPY_MODEL_a039714d71684e82a905363f999c6f79"
      }
     },
     "4305e8088e274b0abc59e9644eebb475": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_799d1e75f17240caa0a02c2dc1015b22",
       "style": "IPY_MODEL_33b12c15a3fa4d16b31c17604880082d",
       "value": " 41/41 [00:00&lt;00:00, 46.64ba/s]"
      }
     },
     "450c5271c14a4d55bdb33990c75f786e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4535b7ce43494673a6842df72a315d8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5a49e6f2889542488a7d2fd766261f23",
       "style": "IPY_MODEL_46bd09f901114683a79d53263ff8e903",
       "value": " 52289/52289 [00:00&lt;00:00, 103035.19 examples/s]"
      }
     },
     "46bd09f901114683a79d53263ff8e903": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5031c7c093754579a64a3111781dd612": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5168c3c1d1d5480ab6fe165ea9602fc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cfb81a577b6540acbb85a1f020097ff6",
       "style": "IPY_MODEL_86b1f0ac45de4ffb8b317a8c948f8265",
       "value": "Generating train split: "
      }
     },
     "556ec5ea37184eb6af1fd9e1cb6d00d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "585d5fdfeb674b55a42f0f33866e4c5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5a49e6f2889542488a7d2fd766261f23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5e03f91cb59d4ad4af22d826b6f63f71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "629ca1be11f04c8295fb3fdf319e96a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "670850c02a6f4cc998a7a4501db99488": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "687459bd792b4eea9eaa90bce65cb367": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "697c19dce3bb4f8984e8c2b2523665a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1ff13d7e83464fdd8aba8cb07a3a1883",
        "IPY_MODEL_f18007bdfe1440d3b4b10779cce98b14",
        "IPY_MODEL_4305e8088e274b0abc59e9644eebb475"
       ],
       "layout": "IPY_MODEL_d36dbba82ed0426794f18ed6aeaf7ebc"
      }
     },
     "6c6183cc0dcb44c7b51f7a907e8d137d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6d2ecf1682374523b1405c9307985f03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "70df3ea676ce4de3aa14e11484bf9882": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fc3dff063ba84df1b3bc56d16dbc1f32",
       "style": "IPY_MODEL_ac258d16e60041d7a499b9e054630324",
       "value": " 60009/60009 [00:00&lt;00:00, 72056.73 examples/s]"
      }
     },
     "723ef1f31da44c15a8fa12c21ce8484a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "799d1e75f17240caa0a02c2dc1015b22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7e4f537798ad43d89ac0a0149611dd4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7ec8704277334b6398183263e0cc9182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_556ec5ea37184eb6af1fd9e1cb6d00d7",
       "style": "IPY_MODEL_cecf77798d3644c09dd1191d0bcc8025",
       "value": " 1/1 [00:00&lt;00:00, 81.37it/s]"
      }
     },
     "814cb063450a416096dad0b32cfd2786": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_723ef1f31da44c15a8fa12c21ce8484a",
       "style": "IPY_MODEL_f1a57501f03c44caa00809a42b6e06d7",
       "value": "Filter: 100%"
      }
     },
     "86b1f0ac45de4ffb8b317a8c948f8265": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "880c62c679f5422f85a7df21ce81ab58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fce5e74b2fc74dad9942218fa5234965",
        "IPY_MODEL_2ace827b7fc244b7ac210dfedb52fb70",
        "IPY_MODEL_8f3e057d6090414b8434e376d855792b"
       ],
       "layout": "IPY_MODEL_b6ac8abfe8c64d84aa14d2a9b798cb12"
      }
     },
     "8af4ce1f33914ea7b53d5d23aaad4cee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8b6566c40dfa41cc92be7941a6984583": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8f2f14ec4106495b8759fed74012ecf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8f3e057d6090414b8434e376d855792b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6c6183cc0dcb44c7b51f7a907e8d137d",
       "style": "IPY_MODEL_6d2ecf1682374523b1405c9307985f03",
       "value": " 166/166 [00:00&lt;00:00, 907.11ba/s]"
      }
     },
     "903adaee46324e46aeee9fed0cb09b7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c8cc9c1fcf314c6992c9e44de281c88e",
       "max": 43566,
       "style": "IPY_MODEL_f58cd3b3d9aa40038583128e18bfdf0a",
       "value": 43566
      }
     },
     "919a6da401ad42f5bba61504052d379d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_1b1f9a847bac4688a828da78d6f027c6",
       "max": 1,
       "style": "IPY_MODEL_f7f43385e3bb42eab31ad0872d468504",
       "value": 1
      }
     },
     "98314a0e14c04fd8ab16b5e40d152e0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "9a9b01e7ff8b447db5cad5f594e0e3e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d2947a86f8943fca886bcedd50e6d7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a039714d71684e82a905363f999c6f79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a075f155b52448b39328946b7f9371c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a3722056ad2a43dba520facbb15e6637": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1903fdb22d374741a21e57b6e5d48ac7",
        "IPY_MODEL_e0401d119a284a95a272d1cf765de085",
        "IPY_MODEL_70df3ea676ce4de3aa14e11484bf9882"
       ],
       "layout": "IPY_MODEL_687459bd792b4eea9eaa90bce65cb367"
      }
     },
     "a37484eee035441bb959e42a67c0977f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a6166f4e27d54f78a83c20a0575d4df9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a9d7a3719fef4f37841c20b2e5b82fdb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ac258d16e60041d7a499b9e054630324": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ada0ea9c24f84764968c0a52feba9e92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a9d7a3719fef4f37841c20b2e5b82fdb",
       "style": "IPY_MODEL_29010c338d38458f859c4311f01b079a",
       "value": "Generating train split: "
      }
     },
     "adc1ea79bac6429897f5e535c94a7cd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_beeee601c84e4c48abe2a98a897792c5",
       "max": 4046,
       "style": "IPY_MODEL_1b7ad33b704a48a38f5370cb18293dd7",
       "value": 4046
      }
     },
     "b032309e20c441ddaf5be7252244779b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b0d6879f4b4641ffb8cd537e1fc59a0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b1fa646bc7304638ac64c976c40a679f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b323979e00ab4ecb9b863071c74fbe4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ada0ea9c24f84764968c0a52feba9e92",
        "IPY_MODEL_fa0c9ab692184f9b90f74c87b2783fe5",
        "IPY_MODEL_dbc84f4c08444fc683be579a02cfe95b"
       ],
       "layout": "IPY_MODEL_670850c02a6f4cc998a7a4501db99488"
      }
     },
     "b35b2dbf88bf4b83b216aecaebca96b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b5e6748ffdf448d0a472e3ecc2221346": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e5794521a0a34800a4cd6c7b9413950a",
       "max": 1,
       "style": "IPY_MODEL_14c96af1dd004f168f2080bd34c2492d",
       "value": 1
      }
     },
     "b6ac8abfe8c64d84aa14d2a9b798cb12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b9560212a7464979828d42e198e1e7ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bdb22c309ede486d927b314b10fee322": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "beeee601c84e4c48abe2a98a897792c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c67c9540a4824ca19ee39cdeae4ce0fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c7214698a5944809bc9091e9ae0ddfcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c76f5899fca245f8ad6bd9037955f491": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dd5877b614c84fa7a44e5bcce7868626",
       "style": "IPY_MODEL_a075f155b52448b39328946b7f9371c7",
       "value": " 52357/52357 [00:02&lt;00:00, 21043.38 examples/s]"
      }
     },
     "c8cc9c1fcf314c6992c9e44de281c88e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cb323e88c7864cb19a0ea00be9349cc7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ce3c41a40a9744f99741e31a976879de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cecf77798d3644c09dd1191d0bcc8025": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cfb81a577b6540acbb85a1f020097ff6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d36dbba82ed0426794f18ed6aeaf7ebc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d6fa8ba68bed4fe9b2d15483c76e2d22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d8ba4e8ab5974be7b5d7d1520a13d2f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5168c3c1d1d5480ab6fe165ea9602fc6",
        "IPY_MODEL_b5e6748ffdf448d0a472e3ecc2221346",
        "IPY_MODEL_1dc03b0b2b2049efa02d9e7c98ee7c7f"
       ],
       "layout": "IPY_MODEL_7e4f537798ad43d89ac0a0149611dd4b"
      }
     },
     "dbc84f4c08444fc683be579a02cfe95b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1f564073f4db4f8fb7dcc6f6f2c76f82",
       "style": "IPY_MODEL_d6fa8ba68bed4fe9b2d15483c76e2d22",
       "value": " 40454/0 [00:00&lt;00:00, 90413.01 examples/s]"
      }
     },
     "dd5877b614c84fa7a44e5bcce7868626": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ddbd5a99657a4c93ba6b2f53bcb56091": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "df76079e34c24e1abcc985d0a117f5a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e03a6202f7704ce092254cc3ad88890d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_194615113ec940e58b7cd643203019d5",
        "IPY_MODEL_080fa2419ade4ec08b17652f360c4c5c",
        "IPY_MODEL_01085c8560be4152be8ab67b4a9284aa"
       ],
       "layout": "IPY_MODEL_2c76bae7f31a4b4db91d2a49ed648479"
      }
     },
     "e0401d119a284a95a272d1cf765de085": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_8af4ce1f33914ea7b53d5d23aaad4cee",
       "max": 60009,
       "style": "IPY_MODEL_b1fa646bc7304638ac64c976c40a679f",
       "value": 60009
      }
     },
     "e35e99b0dc19410b9b336f563283cf58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e5794521a0a34800a4cd6c7b9413950a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "e72194c52849412ebc8c20973026866b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eb545fe0cc154f59a68ecadc8e23599f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f038f9d849ac479f86d63c7971e28cab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f18007bdfe1440d3b4b10779cce98b14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c67c9540a4824ca19ee39cdeae4ce0fa",
       "max": 41,
       "style": "IPY_MODEL_ddbd5a99657a4c93ba6b2f53bcb56091",
       "value": 41
      }
     },
     "f1a57501f03c44caa00809a42b6e06d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f58cd3b3d9aa40038583128e18bfdf0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f6b53f077ab14cc0a6055bfdb34c2549": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f7023110ef0d4b518977a64d7bc3d409": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f7f43385e3bb42eab31ad0872d468504": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fa0c9ab692184f9b90f74c87b2783fe5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_98314a0e14c04fd8ab16b5e40d152e0a",
       "max": 1,
       "style": "IPY_MODEL_2e1efcc879b04464b472d6f5bbeecce8",
       "value": 1
      }
     },
     "fc3dff063ba84df1b3bc56d16dbc1f32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fce5e74b2fc74dad9942218fa5234965": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8f2f14ec4106495b8759fed74012ecf1",
       "style": "IPY_MODEL_9a9b01e7ff8b447db5cad5f594e0e3e4",
       "value": "Creating parquet from Arrow format: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
